{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Author: Christian Camilo Urcuqui LÃ³pez\n",
    "\n",
    "Date: 6 december 2018\n",
    "</b>\n",
    "# Convolutional Neural Networks \n",
    "\n",
    "They are important neural network architecture to resolve problems related with data with more 2D, for example image processing. \n",
    "\n",
    "One important thing to make is to normalize each image, because it helps these gradient calculations stay consistent, for example if we have a resolution of 255 we must divide each pixel to this number and we will have a number between zero to one.\n",
    "\n",
    "Once we have the data normalized the idea is to apply a flattening process (in other words to change the shape or reshape) \n",
    "\n",
    "Let's remember the NMIST dataset of handwritten digits, you can see more information in it's \n",
    "<a href='../../Deep Learning/notMNIST.ipynb'>Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # TODO: compose transforms here\n",
    "dataset = datasets.MNIST('../../../Datasets/MNIST_data/', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ../../../Datasets/MNIST_data/\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cdd2b67d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=25, shuffle=True) # TODO: use the ImageFolder\n",
    "images, labels = next(iter(dataloader))\n",
    "imshow(images[0], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have a image composed by gray pixels, so the next idea is to flatten them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = images[0].view(1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cdd6c152e8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "image = new_img.numpy().transpose()\n",
    "sns.set(rc={'axes.facecolor':'red', 'figure.facecolor':'red'})\n",
    "sns.stripplot(image, palette=sns.dark_palette((260, 75, 60), input=\"husl\"), alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the flattening process, we got a vector composed by the gray pixels, each of them is going to be an input for a neural network "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
